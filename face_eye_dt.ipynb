{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the data\n",
    "import cv2 #(OpenCV)\n",
    "import numpy as np\n",
    "import dlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MI\\AppData\\Local\\Temp\\ipykernel_10616\\2841309542.py:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    }
   ],
   "source": [
    "#Using HAAR Cascade Classifier\n",
    "face_cf = cv2.CascadeClassifier('C:\\\\Computer_vision\\\\opencv\\\\data\\\\haarcascades\\\\haarcascade_frontalface_default.xml')\n",
    "\n",
    "#Load the image\n",
    "img = cv2.imread('C:\\\\Computer_vision\\\\Vk.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cf.detectMultiScale(gray,1.3,5)\n",
    "print(type(faces))\n",
    "\n",
    "if faces is ():\n",
    "  print(\"No faces found in the given image.\")\n",
    "\n",
    "for x,y,w,h in faces:\n",
    "  cv2.rectangle(img,(x,y),(x+w,y+h),(112,0,0),2)\n",
    "  cv2.imshow('Face Detection',img) #--- This line of code is depreciated in google colab as it's facing issues crashing the jupyter Notebook\n",
    "#   cv2_imshow(img)\n",
    "  cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Face and Eye Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:12: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:12: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\MI\\AppData\\Local\\Temp\\ipykernel_10616\\2767679419.py:12: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    }
   ],
   "source": [
    "#Using HAAR Cascade Classifier\n",
    "face_cf = cv2.CascadeClassifier('C:\\\\Computer_vision\\\\opencv\\\\data\\\\haarcascades\\\\haarcascade_frontalface_default.xml')\n",
    "\n",
    "eye_cf = cv2.CascadeClassifier('C:\\\\Computer_vision\\\\opencv\\\\data\\\\haarcascades\\\\haarcascade_eye.xml')\n",
    "\n",
    "#Load the image\n",
    "img = cv2.imread('C:\\\\Computer_vision\\\\Vk.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cf.detectMultiScale(gray,1.3,5)\n",
    "\n",
    "if faces is ():\n",
    "  print(\"No faces found in the given image.\")\n",
    "\n",
    "for x,y,w,h in faces:\n",
    "  cv2.rectangle(img,(x,y),(x+w,y+h),(112,0,0),2)\n",
    "  cv2.imshow('Face Detection',img) #--- This line of code is depreciated in google colab as it's facing issues crashing the jupyter Notebook\n",
    "  # cv2_imshow(img)\n",
    "  # cv2.waitKey(1500)\n",
    "  roi_gray = gray[y:y+h,x:x+w]\n",
    "  roi_color = img[y:y+h,x:x+w]\n",
    "  \n",
    "  eyes = eye_cf.detectMultiScale(roi_gray,1.1,3)\n",
    "  #Eye capturing\n",
    "  for (ex,ey,ew,eh) in eyes:\n",
    "    cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,180,0),2)\n",
    "    cv2.imshow('Face and eye',img)\n",
    "    # cv2_imshow(img)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect Face and Eye from the video (Webcam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_eye_dt(gray,img):\n",
    "  faces = face_cf.detectMultiScale(gray,1.3,5)\n",
    "  for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(118,0,0),2)\n",
    "    roi_gray = gray[y:y+h,x:x+w]\n",
    "    roi_img = img[y:y+h,x:x+w]\n",
    "\n",
    "    eyes = eye_cf.detectMultiScale(roi_gray,1.1,3)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "      cv2.rectangle(roi_img,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Video initialization\n",
    "video_cpt = cv2.VideoCapture(0) # 0 --> To user inbuilt webcam, 1 --> To use external webcam\n",
    "\n",
    "while True:\n",
    "  ret,frame = video_cpt.read()\n",
    "  #If frame is read correctly ret is True\n",
    "  if ret is not True:\n",
    "    print(\"Can't read the frame, Exiting...\")\n",
    "    break\n",
    "  gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "  live_vd = face_eye_dt(gray,frame)\n",
    "  cv2.imshow('Video',live_vd)\n",
    "  if cv2.waitKey(0) or ord('q'):\n",
    "    break\n",
    "\n",
    "video_cpt.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect the center of pupil and track its movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't read the frame, Exiting...\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('eye_motion_tracking\\eye_recording.flv')\n",
    "\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    if ret is not True:\n",
    "        print(\"Can't read the frame, Exiting...\")\n",
    "        break\n",
    "\n",
    "    roi = frame[269:795,537:1416]\n",
    "    rows,cols,clr = roi.shape\n",
    "    gray_roi = cv2.cvtColor(roi,cv2.COLOR_BGR2GRAY)\n",
    "    gray_roi_blur = cv2.GaussianBlur(gray_roi,(7,7),0) #(7,7) is the kernel size (more is the number more blur)\n",
    "    \n",
    "\n",
    "    _,threshold = cv2.threshold(gray_roi_blur,3,255,cv2.THRESH_BINARY_INV)\n",
    "    contours,heirr = cv2.findContours(threshold,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # print(contours)\n",
    "\n",
    "    sorted_contours = sorted(contours, key = lambda x: cv2.contourArea(x), reverse=True)\n",
    "    for i in sorted_contours:\n",
    "        (x,y,w,h) = cv2.boundingRect(i)\n",
    "        cv2.rectangle(roi,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "        cv2.line(roi,(x+int(w/2),0),(x+int(w/2),rows),(0,255,0),2) #Horizontal line from the center of pupil\n",
    "        cv2.line(roi,(0,y+int(h/2)),(cols,y+int((h/2))),(0,255,0),2) #Vertical line from center of pupil\n",
    "        break\n",
    "\n",
    "\n",
    "    cv2.imshow('Gray roi',gray_roi)\n",
    "    cv2.imshow('Blur gray roi',gray_roi_blur)\n",
    "    cv2.imshow('threshold',threshold)\n",
    "    cv2.imshow('ROI',roi)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out with webcam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "from math import hypot\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd = cv2.VideoCapture(0)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "while True:\n",
    "    ret,frame = vd.read()\n",
    "    new_frame = np.zeros((500,500,3),np.uint8)\n",
    "    if ret is not True:\n",
    "        print(\"Cant read the frame, Exiting...\")\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "    def mid_point(p1,p2):\n",
    "        return int((p1.x+p2.x)/2), int((p1.y+p2.y)/2)\n",
    "    \n",
    "    #To detect the Blinking (by taking the ratio to horizontal and vertical line)\n",
    "    \n",
    "    def get_blink_ratio(eye_points,facial_landmarks):\n",
    "        #Left or Right Eye points\n",
    "        left_point = (facial_landmarks.part(eye_points[0]).x,facial_landmarks.part(eye_points[0]).y)\n",
    "        right_point = (facial_landmarks.part(eye_points[3]).x,facial_landmarks.part(eye_points[3]).y)\n",
    "        top_point = (mid_point(facial_landmarks.part(eye_points[1]),facial_landmarks.part(eye_points[2])))\n",
    "        bottom_point = (mid_point(facial_landmarks.part(eye_points[5]),facial_landmarks.part(eye_points[4])))\n",
    "\n",
    "        #lines\n",
    "        hor_line = cv2.line(frame,left_point,right_point,(0,122,0),2)\n",
    "        ver_line = cv2.line(frame,top_point,bottom_point,(0,122,0),2)\n",
    "\n",
    "        #Distance\n",
    "        hor_length = hypot((left_point[0]-right_point[0]),(left_point[1]-right_point[1]))\n",
    "        ver_length = hypot((top_point[0]-bottom_point[0]),(top_point[1]-bottom_point[1]))\n",
    "\n",
    "        #Ratio\n",
    "        blink_ratio = hor_length/ver_length\n",
    "\n",
    "        return blink_ratio\n",
    "    \n",
    "    #To Track the eye movement (Gaze Ratio)\n",
    "    def gaze_ratio(eye_points,facial_landmarks):\n",
    "        eye_region = np.array([(facial_landmarks.part(eye_points[0]).x, facial_landmarks.part(eye_points[0]).y),\n",
    "                                (facial_landmarks.part(eye_points[1]).x, facial_landmarks.part(eye_points[1]).y),\n",
    "                                (facial_landmarks.part(eye_points[2]).x, facial_landmarks.part(eye_points[2]).y),\n",
    "                                (facial_landmarks.part(eye_points[3]).x, facial_landmarks.part(eye_points[3]).y),\n",
    "                                (facial_landmarks.part(eye_points[4]).x, facial_landmarks.part(eye_points[4]).y),\n",
    "                                (facial_landmarks.part(eye_points[5]).x, facial_landmarks.part(eye_points[5]).y)], np.int32)\n",
    "        \n",
    "        height,width,_ = frame.shape\n",
    "        mask = np.zeros((height,width),np.uint8)\n",
    "        cv2.polylines(mask,[eye_region],True,255,2)\n",
    "        cv2.fillPoly(mask,[eye_region],255)\n",
    "        eye = cv2.bitwise_and(gray,gray,mask=mask)\n",
    "\n",
    "        min_x = np.min(eye_region[:,0])\n",
    "        max_x = np.max(eye_region[:,0])\n",
    "        min_y = np.min(eye_region[:,1])\n",
    "        max_y = np.max(eye_region[:,1])\n",
    "\n",
    "        gray_eye = eye[min_y:max_y,min_x:max_x]\n",
    "\n",
    "        #THreshold\n",
    "        _,threshold_eye = cv2.threshold(gray_eye,70,255,cv2.THRESH_BINARY)\n",
    "        ht,wt = threshold_eye.shape\n",
    "        total_px = ht*wt\n",
    "\n",
    "        #left side white\n",
    "        left_side_threshold = threshold_eye[0:ht,0:int(wt/2)]\n",
    "        left_side_white =  cv2.countNonZero(left_side_threshold)\n",
    "\n",
    "        # r = total_px - left_side_white\n",
    "\n",
    "        #right side white\n",
    "        right_side_threshold = threshold_eye[0:ht,int(wt/2):wt]\n",
    "        right_side_white = cv2.countNonZero(right_side_threshold)\n",
    "\n",
    "        # l = total_px - right_side_white\n",
    "\n",
    "\n",
    "        # if left_side_white == 0:\n",
    "        #     gazeratio = 0.9\n",
    "        if right_side_white == 0:\n",
    "            gazeratio = 3\n",
    "        else:\n",
    "            gazeratio = left_side_white/right_side_white\n",
    "        return gazeratio\n",
    "    \n",
    "    for face in faces:\n",
    "        # x,y = face.left(),face.top()\n",
    "        # x1,y1 = face.right(),face.bottom()\n",
    "\n",
    "        # cv2.rectangle(frame,(x,y),(x1,y1),(0,122,0),2)\n",
    "\n",
    "        landmarks = predictor(gray,face)\n",
    "\n",
    "        #Taking avg of left and right eye blink ratio\n",
    "        left_eye_blink = get_blink_ratio([36,37,38,39,40,41],landmarks)\n",
    "        right_eye_blink = get_blink_ratio([42,43,44,45,46,47],landmarks)\n",
    "\n",
    "        avg_blink_ratio = (left_eye_blink+right_eye_blink)/2\n",
    "\n",
    "        if avg_blink_ratio > 4.6:\n",
    "            cv2.putText(frame,\"Blinking\",(60,90),font,2,(0,0,122))\n",
    "\n",
    "        #Left eye\n",
    "        left_point = (landmarks.part(36).x,landmarks.part(36).y)\n",
    "        right_point = (landmarks.part(39).x,landmarks.part(39).y)\n",
    "        top_point = (mid_point(landmarks.part(37),landmarks.part(38)))\n",
    "        bottom_point = (mid_point(landmarks.part(41),landmarks.part(40)))\n",
    "        \n",
    "        #lines\n",
    "        hor_line = cv2.line(frame,left_point,right_point,(0,122,0),2)\n",
    "        ver_line = cv2.line(frame,top_point,bottom_point,(0,122,0),2)\n",
    "\n",
    "        #To track the gaze ratio as the avg of both left and right eye\n",
    "        gaze_ratio_left_eye = gaze_ratio([36,37,38,39,40,41],landmarks)\n",
    "        gaze_ratio_right_eye = gaze_ratio([42,43,44,45,46,47],landmarks)\n",
    "\n",
    "        avg_gaze_ratio = (gaze_ratio_left_eye+gaze_ratio_right_eye)/2\n",
    "        # avg_gaze_ratio = (gaze_ratio_left_eye/gaze_ratio_right_eye)\n",
    "\n",
    "        # r,l = gaze_ratio([36,37,38,39,40,41],landmarks)\n",
    "\n",
    "        # if r>l:\n",
    "        #     cv2.putText(frame,\"Looking Left\",(20,40),font,2,(0,0,220),2)\n",
    "        #     new_frame[:] = (0,0,220)\n",
    "        # elif l>r:\n",
    "        #     cv2.putText(frame,\"Looking Right\",(20,40),font,2,(0,0,220),2)\n",
    "        #     new_frame[:] = (220,0,0)\n",
    "        # else:\n",
    "        #     cv2.putText(frame,\"Center\",(20,40),font,2,(0,0,220),2)\n",
    "\n",
    "        if avg_gaze_ratio < 0.6:\n",
    "            cv2.putText(frame,\"Looking Right\",(20,40),font,2,(0,0,220),2)\n",
    "            new_frame[:] = (0,0,220)\n",
    "        elif (0.6<=avg_gaze_ratio<=1.5):\n",
    "            cv2.putText(frame,\"Center\",(20,40),font,2,(0,0,220),2)\n",
    "        else:\n",
    "            cv2.putText(frame,\"Looking Left\",(20,40),font,2,(0,0,220),2)\n",
    "            new_frame[:] = (220,0,0)\n",
    "\n",
    "    cv2.imshow(\"frame\",frame)\n",
    "    cv2.imshow(\"new_frame\",new_frame)\n",
    "    \n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "vd.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Computer_vision\\face_eye_dt.ipynb Cell 12\u001b[0m in \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Computer_vision/face_eye_dt.ipynb#X25sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39m# cv2.imshow('Gray roi',gray_roi)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Computer_vision/face_eye_dt.ipynb#X25sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39m# cv2.imshow('Blur gray roi',gray_roi_blur)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Computer_vision/face_eye_dt.ipynb#X25sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39m# cv2.imshow('threshold',threshold)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Computer_vision/face_eye_dt.ipynb#X25sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mROI\u001b[39m\u001b[39m'\u001b[39m,roi)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Computer_vision/face_eye_dt.ipynb#X25sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Computer_vision/face_eye_dt.ipynb#X25sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39m# key = cv2.waitKey(30)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Computer_vision/face_eye_dt.ipynb#X25sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     \u001b[39m# if key == 27:\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Computer_vision/face_eye_dt.ipynb#X25sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39m#     break\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Computer_vision/face_eye_dt.ipynb#X25sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39m# if cv2.waitKey(0) or ord('q'):\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Computer_vision/face_eye_dt.ipynb#X25sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     \u001b[39m#     break\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Computer_vision/face_eye_dt.ipynb#X25sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    if ret is not True:\n",
    "        print(\"Can't read the frame, Exiting...\")\n",
    "        break\n",
    "\n",
    "    # roi = frame[269:795,537:1416]\n",
    "    roi = frame[100:1000,200:1000]\n",
    "    rows,cols,clr = roi.shape\n",
    "    gray_roi = cv2.cvtColor(roi,cv2.COLOR_BGR2GRAY)\n",
    "    gray_roi_blur = cv2.GaussianBlur(gray_roi,(7,7),0) #(7,7) is the kernel size (more is the number more blur)\n",
    "    \n",
    "\n",
    "    _,threshold = cv2.threshold(gray_roi_blur,3,255,cv2.THRESH_BINARY_INV)\n",
    "    contours,heirr = cv2.findContours(threshold,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # print(contours)\n",
    "\n",
    "    sorted_contours = sorted(contours, key = lambda x: cv2.contourArea(x), reverse=True)\n",
    "    for i in sorted_contours:\n",
    "        (x,y,w,h) = cv2.boundingRect(i)\n",
    "        cv2.rectangle(roi,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "        cv2.line(roi,(x+int(w/2),0),(x+int(w/2),rows),(0,255,0),2) #Horizontal line from the center of pupil\n",
    "        cv2.line(roi,(0,y+int(h/2)),(cols,y+int((h/2))),(0,255,0),2) #Vertical line from center of pupil\n",
    "        break\n",
    "\n",
    "\n",
    "    # cv2.imshow('Gray roi',gray_roi)\n",
    "    # cv2.imshow('Blur gray roi',gray_roi_blur)\n",
    "    # cv2.imshow('threshold',threshold)\n",
    "    cv2.imshow('ROI',roi)\n",
    "    cv2.waitKey(0)\n",
    "    # key = cv2.waitKey(30)\n",
    "    # if key == 27:\n",
    "    #     break\n",
    "    # if cv2.waitKey(0) or ord('q'):\n",
    "    #     break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Computer_vision\\face_eye_dt.ipynb Cell 15\u001b[0m in \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Computer_vision/face_eye_dt.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     cv2\u001b[39m.\u001b[39mimshow(\u001b[39m\"\u001b[39m\u001b[39mFace Detect\u001b[39m\u001b[39m\"\u001b[39m,img)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Computer_vision/face_eye_dt.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m# if cv2.waitKey(1) or 0xFF == ('q'):\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Computer_vision/face_eye_dt.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m#     break\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Computer_vision/face_eye_dt.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mif\u001b[39;00m cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m1\u001b[39;49m) \u001b[39m&\u001b[39m \u001b[39m0xFF\u001b[39m \u001b[39m==\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mq\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Computer_vision/face_eye_dt.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Computer_vision/face_eye_dt.ipynb#X26sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m vd\u001b[39m.\u001b[39mrelease()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "vd = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret,img = vd.read()\n",
    "    if ret is not True:\n",
    "        print(\"No frame detected, Exit\")\n",
    "        break\n",
    "\n",
    "    cv2.imshow(\"Face Detect\",img)\n",
    "    # if cv2.waitKey(1) or 0xFF == ('q'):\n",
    "    #     break\n",
    "    if cv2.waitKey(1) & 0xFF == ('q'):\n",
    "        break\n",
    "\n",
    "vd.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cnt in sorted_contours:\n",
    "    # (x,y,w,h) = cv2.drawContours(roi,[cnt],-1,(0,0,255),2) #--> To draw the contours\n",
    "    (x,y,w,h) = cv2.boundingRect(cnt)\n",
    "    cv2.rectangle(roi,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "\n",
    "    cv2.imshow('roi',roi)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Video initialization\n",
    "video_cpt = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "  ret,frame = video_cpt.read()\n",
    "  #If frame is read correctly ret is True\n",
    "  if ret is not True:\n",
    "    print(\"Can't read the frame, Exiting...\")\n",
    "    break\n",
    "  gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "  live_vd = face_eye_dt(gray,frame)\n",
    "  cv2.imshow('Video',live_vd)\n",
    "  if cv2.waitKey(0) or ord('q'):\n",
    "    break\n",
    "\n",
    "video_cpt.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
